name: Run Benchmark

on:
  push:
    paths:
      - 'data/models.yaml'
      - 'data/tasks/**'
  pull_request:
    paths:
      - 'data/models.yaml'
      - 'data/tasks/**'
  workflow_dispatch:
    inputs:
      models:
        description: 'Comma-separated list of model IDs to benchmark (leave empty for all)'
        required: false
        type: string
      tasks:
        description: 'Comma-separated list of task IDs to run (leave empty for all)'
        required: false
        type: string

jobs:
  benchmark:
    runs-on: ubuntu-latest
    
    permissions:
      contents: write
      actions: read
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 2  # Fetch at least 2 commits to compare changes
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run benchmark
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        GOOGLE_APPLICATION_CREDENTIALS: ${{ secrets.GOOGLE_APPLICATION_CREDENTIALS }}
      run: |
        # Check if models.yaml was changed to run test models
        if git diff --name-only HEAD HEAD~1 | grep -q "data/models.yaml"; then
          echo "models.yaml changed - running test models on 30 random tasks..."
          # Get all test models from models.yaml
          TEST_MODELS=$(python -c "
import yaml
with open('data/models.yaml', 'r') as f:
    models = yaml.safe_load(f)['models']
test_models = [m['id'] for m in models if '-test' in m['id']]
print(','.join(test_models))
          ")
          echo "Running test models: $TEST_MODELS"
          python scripts/run_benchmark.py \
            --models "$TEST_MODELS" \
            --limit 30
        else
          # Default limited test
          echo "Running limited test benchmark with gpt-4o-mini-test..."
          python scripts/run_benchmark.py \
            --models "gpt-4o-mini-test" \
            --tasks "mapwise-usa-8808,example_weather,cf-imaginary-map-13283"
        fi
    
    - name: Upload results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results
        path: data/results/
    
    - name: Commit updated results
      if: github.event_name == 'push' && github.ref == 'refs/heads/main'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add data/results/
        git diff --staged --quiet || git commit -m "Update benchmark results [skip ci]"
        git push